{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w-okada/asrclient/blob/master/w_okada's_ASR_Client.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNCGmSXbfZRr"
      },
      "source": [
        "### w-okada's Automated Speech Recognition Client  | **Google Colab**\n",
        "\n",
        "## READ ME - VERY IMPORTANT\n",
        "This is an attempt to run [Text To Speech Client](https://github.com/w-okada/asr-client) on Google Colab, still not perfect but is totally usable.\n",
        "\n",
        "---\n",
        "\n",
        "###Always use Colab GPU (**VERY VERY VERY IMPORTANT!**)\n",
        "You need to use a Colab GPU so the Voice Changer can work faster and better\\\n",
        "Use the menu above and click on **Runtime** » **Change runtime** » **Hardware acceleration** to select a GPU (**T4 is the free one**)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GYWTHWmRIY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#=================Updated=================\n",
        "# @title **[1]** Clone repository and install dependencies\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.(~5min)**\n",
        "\n",
        "#@markdown ---\n",
        "# @markdown By using Google Drive, you can avoid re-downloading already downloaded versions. \"/content/drive/MyDrive/asrclient\" is used as working directory.\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import threading\n",
        "import shutil\n",
        "import base64\n",
        "import codecs\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "from typing import Literal, TypeAlias\n",
        "\n",
        "%cd /content\n",
        "\n",
        "\n",
        "# Configs\n",
        "Run_Cell=0\n",
        "GOOGLE_DRIVE_WORKDIR = \"/content/drive/MyDrive/asr-client\"\n",
        "Use_Drive=False #@param {type:\"boolean\"}\n",
        "Initialize_Working_Directory=False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "current_version_hash=None\n",
        "latest_version_hash=None\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU is not available\")\n",
        "    # sys.exit(\"No GPU available. Change runtime.\")\n",
        "\n",
        "\n",
        "notebook_env=0\n",
        "if os.path.exists('/content'):\n",
        "  notebook_env=1\n",
        "  print(\"Welcome to Colab Mode\")\n",
        "  from google.colab import drive\n",
        "\n",
        "elif os.path.exists('/kaggle/working'):\n",
        "  notebook_env=2\n",
        "  print(\"Welcome to Kaggle Mod\")\n",
        "else:\n",
        "  notebook_env=3\n",
        "  print(\"Welcome!\")\n",
        "\n",
        "from IPython.display import clear_output, Javascript\n",
        "\n",
        "if notebook_env==1 and Use_Drive==True:\n",
        "  work_dir = GOOGLE_DRIVE_WORKDIR\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  if Initialize_Working_Directory:\n",
        "    user_input = input(f\"Are you sure you want to delete the working directory '{GOOGLE_DRIVE_WORKDIR}'? (y/n): \").strip().lower()\n",
        "    if user_input == 'y':\n",
        "        print(f\"Deleting {GOOGLE_DRIVE_WORKDIR}\")\n",
        "        !rm -r {GOOGLE_DRIVE_WORKDIR}\n",
        "    else:\n",
        "        print(\"Skipping deletion of working directory.\")\n",
        "\n",
        "\n",
        "  if not os.path.exists(work_dir):\n",
        "    !mkdir -p {work_dir}\n",
        "\n",
        "  print(\"Checking latest version...\")\n",
        "  if os.path.exists(f'{work_dir}/latest_hash.txt'):\n",
        "    current_version_hash = open(f'{work_dir}/latest_hash.txt').read().strip()\n",
        "  else:\n",
        "    current_version_hash = None\n",
        "\n",
        "  !curl -s -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/latest_hash.txt -o latest_hash.txt\n",
        "  latest_version_hash = open('latest_hash.txt').read().strip()\n",
        "\n",
        "  print(f\"current_version_hash: {current_version_hash}\")\n",
        "  print(f\"latest_version_hash : {latest_version_hash}\")\n",
        "\n",
        "  if current_version_hash != latest_version_hash:\n",
        "    print(f\"hash not match -> download latest version\")\n",
        "\n",
        "    latest_hash_path=f'{work_dir}/latest_hash.txt'\n",
        "\n",
        "    !curl -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/asrclient_latest_for_colab -o {work_dir}/asrclient_latest_for_colab\n",
        "    !curl -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/web_front_latest.zip -o {work_dir}/web_front_latest.zip\n",
        "\n",
        "    !cp latest_hash.txt {latest_hash_path}\n",
        "    print(\"Download is done.\")\n",
        "  else:\n",
        "    print(\"hash matched. skip download\")\n",
        "\n",
        "else:\n",
        "  work_dir = \"/content\"\n",
        "  print(\"Downloading the latest asrclient... \")\n",
        "  !curl -s -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/latest_hash.txt -o latest_hash.txt\n",
        "  latest_version_hash = open('latest_hash.txt').read().strip()\n",
        "\n",
        "  !curl -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/asrclient_latest_for_colab -o {work_dir}/asrclient_latest_for_colab\n",
        "  !curl -L https://huggingface.co/wok000/asrclient000_colab/resolve/main/web_front_latest.zip -o {work_dir}/web_front_latest.zip\n",
        "\n",
        "  print(\"Download is done.\")\n",
        "\n",
        "\n",
        "#### MOVE TO WORK DIR ###\n",
        "%cd {work_dir}\n",
        "!chmod 0700 asrclient_latest_for_colab\n",
        "\n",
        "print(\"Installing modules... \",end=\"\")\n",
        "!sudo apt-get install -y libportaudio2 > /dev/null 2>&1\n",
        "!pip install  pyngrok > /dev/null 2>&1\n",
        "print(\"Install is done.\")\n",
        "\n",
        "Run_Cell=1\n",
        "\n",
        "!unzip -qq -o  web_front_latest.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7mYqKtW6VOI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **[2]** Start server (~ 3min)\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (2~4 minutes)\n",
        "\n",
        "# @markdown If you want to use ngrok, please input your token in the option section below. If you encounter a 403 error with the colab proxy, using ngrok can sometimes help to work around it.\n",
        "# @markdown https://dashboard.ngrok.com/\n",
        "\n",
        "# @markdown And if you cannot use ngrok, you can use the cell client (experimental). Run the cell below.\n",
        "\n",
        "\n",
        "# @markdown ### Options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "Play_Notification = True  # @param {type:\"boolean\"}\n",
        "NgrokToken = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "PORT=8010\n",
        "NGROK_URL_FILE = \"ngrok_url.txt\"\n",
        "\n",
        "LOG_FILE = f\"/content/LOG_FILE_{PORT}.log\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "def play_notification_sound(url):\n",
        "    display(Audio(url=url, autoplay=True))\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if NgrokToken ==\"\":\n",
        "  get_ipython().system_raw(f'LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./asrclient_latest_for_colab cui --port {PORT} --no_cui true --https False >{LOG_FILE} 2>&1 &')\n",
        "else:\n",
        "  # get_ipython().system_raw(f'LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./asrclient_latest_for_colab cui --port {PORT} --no_cui true --https False --ngrok_token {NgrokToken} --ngrok_proxy_url_file {NGROK_URL_FILE} >{LOG_FILE} 2>&1 &')\n",
        "  get_ipython().system_raw(f'./asrclient_latest_for_colab cui --port {PORT} --no_cui true --https False --ngrok_token {NgrokToken} --ngrok_proxy_url_file {NGROK_URL_FILE} >{LOG_FILE} 2>&1 &')\n",
        "\n",
        "\n",
        "import socket\n",
        "def wait_for_server():\n",
        "  elapsed_time = 0\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  while True:\n",
        "      time.sleep(1)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "      if result == 0:\n",
        "          break\n",
        "      sock.close()\n",
        "      # 時刻を出力\n",
        "      current_time = time.time()\n",
        "      elapsed_time = int(current_time - start_time)\n",
        "      clear_output(wait=True)\n",
        "      print(f\"Waiting for server... elapsed: {elapsed_time}sec\")\n",
        "      try:\n",
        "        with open(LOG_FILE, 'r') as f:\n",
        "            lines = f.readlines()[-5:]\n",
        "            for line in lines:\n",
        "                print(line.strip())\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  if ClearConsole:\n",
        "      clear_output()\n",
        "  print(\"--------- SERVER READY! ---------\")\n",
        "  print(f\"Your server is available. elapsed: {elapsed_time}sec\")\n",
        "  proxy = eval_js( \"google.colab.kernel.proxyPort(\" + str(PORT) + \")\" )\n",
        "  print(f\"colab proxy: {proxy}\")\n",
        "  if NgrokToken != \"\":\n",
        "    with open(NGROK_URL_FILE, \"r\") as f:\n",
        "      ngrok_url = f.read().strip()\n",
        "    print(f\"Ngrok URL: {ngrok_url}\")\n",
        "  print(\"---------------------------------\")\n",
        "  if Play_Notification==True:\n",
        "    play_notification_sound('https://huggingface.co/wok000/voices/resolve/main/the_application_is_ready.wav')\n",
        "wait_for_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fIqxDo-rSkrR"
      },
      "outputs": [],
      "source": [
        "# @title **[3]** Start Cell Client (Experimental)\n",
        "# @markdown Launch the client within the cell. This can be used if proxy or ngrok cannot be used.If the behavior is unstable, re-running the cell may resolve the issue.\n",
        "\n",
        "from IPython.display import HTML, SVG,Javascript\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "def dojs3():\n",
        "  return HTML(f\"\"\"\n",
        "<script>var colab_server_port={PORT}</script>\n",
        "<script>var colab_server=1</script>\n",
        "<script defer=\"defer\" src=\"http://localhost:{PORT}/index.js\"></script>\n",
        "<div id=\"app\" style=\"width:100%;height:100%\"></div>\n",
        "  \"\"\")\n",
        "dojs3()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4z0DLfvJVzT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8IpNBf85YADDmdgzm+AYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}